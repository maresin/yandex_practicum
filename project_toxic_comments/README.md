## Проект "Поиск токсичных комментариев"
Данная работа является учебным проектом и выполняется по завершении спринта "Машинное обучение для текстов"  на курсе _"Специалист по Data Science"_ образовательной платформы _Яндекс.Практикум_.    

### Задача:
Создать модель для классификации комментариев пользователей на позитивные и негативные для интернет-магазина. Значение качества целевой метрики _F1_ должны быть не меньше 0.75. 
### Данные:
В наличии имеются данные с разметкой о токсичности комментариев:  
- _Текст комментария_
- _Отметка о токсичности_
### Используемые библиотеки:  
*Pandas, NumPy, RE, NLTK, VADER, Scikit-learn, Optuna, LightGBM, Pandarallel*
### Сделано:
Для решения задачи был реализован механизм создания дополнительных предикторов на основе корпуса имеющихся текстов с использованием методов векторизации текстов _Bag-of-Words_ и _TF-IDF_. Перед непосредственно векторизацией тексты были разбиты на токены, из которых были получены леммы. Для данной обработки были использованы инструменты библиотеки _NLTK_. Из-за большого числа признаков был проведен отбор наиболее значимых из них с помощью `SelectKBest` библиотеки _Scikit-learn_. Для осуществления классифицирования над новым пространством признаков было использовано несколько моделей разных типов. Для подбора гиперпараметров модели была использована библиотека _Optuna_.  
По итогам сравнения была выбрана модель на основе _LGBMClassifier_ показала достаточно хорошую точность распознавания токсичных комментариев (_F1-мера_ = 0.78).  
Также была рассмотрена возможность внесения дополнительных признаков, сгенерированных с помощью предобученной модели _VADER_ из набора _NLTK_. Это было реализовано средствами ООП модуля _Scikit-learn_ - созданы несколько дочерних классов и сложных пайплайн на их основе.  

⚠ _Внимание:_ Так как на платформе GitHub существуют запрет использования JavaScript, то просмотр полной версии проекта с визуализацией возможен лишь локально через скачивание файла `toxic_comments_page.html`.
